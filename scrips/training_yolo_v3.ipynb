{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f44afb53",
        "outputId": "fb11d597-2c4b-42d8-8650-d84d0b8d67a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolo-v3-by-tensorflow'...\n",
            "remote: Enumerating objects: 489, done.\u001b[K\n",
            "remote: Counting objects: 100% (213/213), done.\u001b[K\n",
            "remote: Compressing objects: 100% (151/151), done.\u001b[K\n",
            "remote: Total 489 (delta 108), reused 128 (delta 49), pack-reused 276 (from 1)\u001b[K\n",
            "Receiving objects: 100% (489/489), 55.47 MiB | 32.68 MiB/s, done.\n",
            "Resolving deltas: 100% (256/256), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/thanhhoai2k4/yolo-v3-by-tensorflow.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbwZmBWRQOSX"
      },
      "outputs": [],
      "source": [
        "! mv yolo-v3-by-tensorflow/* ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fa5a3c4"
      },
      "outputs": [],
      "source": [
        "! rm -r data\n",
        "! rm -r val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz4ncpMUQ-ZE",
        "outputId": "73839ab2-2767-44ec-cb2e-4db087d9cb0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/andrewmvd/face-mask-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 398M/398M [00:10<00:00, 39.9MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/andrewmvd/face-mask-detection/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"andrewmvd/face-mask-detection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "b9b88964"
      },
      "outputs": [],
      "source": [
        "! cp -r \"$path\" ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9200385e"
      },
      "outputs": [],
      "source": [
        "! mv 1 data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIBl-OBOiteF",
        "outputId": "4528fe2b-28a3-4c0a-a1ee-37db4c17a5e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Các thư mục đích 'val/annotations' và 'val/images' đã sẵn sàng.\n",
            "\n",
            "Tổng số cặp file: 853\n",
            "Sẽ di chuyển 170 cặp vào thư mục validation...\n",
            "\n",
            "Hoàn tất! Đã di chuyển 170 cặp ảnh/XML.\n"
          ]
        }
      ],
      "source": [
        "# !python conver_yolo2pacan.py\n",
        "!python scrips/create_val.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "shzVY3xKSTOV",
        "outputId": "186986a0-4734-4812-aa5c-d1ca0532bd7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-07-02 09:24:23.332324: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751448263.353228    1117 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751448263.359502    1117 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-02 09:24:23.379980: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-07-02 09:24:27.970392: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1751448267.972772    1117 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "create a new model yolo v3 !\n",
            "Epoch 1/100\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor']\n",
            "Received: inputs=Tensor(shape=(None, 416, 416, 3))\n",
            "  warnings.warn(msg)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1751448313.085797    1154 service.cc:148] XLA service 0x78db741c5f30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1751448313.085924    1154 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-07-02 09:25:15.560934: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1751448319.778572    1154 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
            "2025-07-02 09:25:33.121919: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:378] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
            "I0000 00:00:1751448365.694487    1154 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683ms/step - conv2d_58_loss: 44.4455 - conv2d_66_loss: 268.5416 - conv2d_74_loss: 1164.4424 - loss: 1480.9381libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 10040.25488, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 1s/step - conv2d_58_loss: 44.0154 - conv2d_66_loss: 265.4504 - conv2d_74_loss: 1151.0454 - loss: 1464.0271 - val_conv2d_58_loss: 9107.1455 - val_conv2d_66_loss: 171.2236 - val_conv2d_74_loss: 757.7201 - val_loss: 10040.2549\n",
            "Epoch 2/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698ms/step - conv2d_58_loss: 25.0982 - conv2d_66_loss: 53.1182 - conv2d_74_loss: 125.2147 - loss: 207.6183libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 2: val_loss improved from 10040.25488 to 605.13684, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 933ms/step - conv2d_58_loss: 24.9880 - conv2d_66_loss: 53.1212 - conv2d_74_loss: 125.0378 - loss: 207.3348 - val_conv2d_58_loss: 36.6590 - val_conv2d_66_loss: 91.4935 - val_conv2d_74_loss: 472.7219 - val_loss: 605.1368\n",
            "Epoch 3/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712ms/step - conv2d_58_loss: 22.6594 - conv2d_66_loss: 48.6912 - conv2d_74_loss: 84.2307 - loss: 159.8402libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 3: val_loss improved from 605.13684 to 327.25153, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 932ms/step - conv2d_58_loss: 22.6067 - conv2d_66_loss: 48.6956 - conv2d_74_loss: 84.0318 - loss: 159.5928 - val_conv2d_58_loss: 21.9746 - val_conv2d_66_loss: 89.9590 - val_conv2d_74_loss: 211.1036 - val_loss: 327.2515\n",
            "Epoch 4/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721ms/step - conv2d_58_loss: 20.8908 - conv2d_66_loss: 50.8974 - conv2d_74_loss: 68.5985 - loss: 144.5778libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 4: val_loss improved from 327.25153 to 235.29443, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 887ms/step - conv2d_58_loss: 20.8760 - conv2d_66_loss: 50.8867 - conv2d_74_loss: 68.4834 - loss: 144.4367 - val_conv2d_58_loss: 23.8117 - val_conv2d_66_loss: 102.2962 - val_conv2d_74_loss: 105.0694 - val_loss: 235.2944\n",
            "Epoch 5/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735ms/step - conv2d_58_loss: 25.2466 - conv2d_66_loss: 46.3542 - conv2d_74_loss: 54.5845 - loss: 130.2950libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 5: val_loss did not improve from 235.29443\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 829ms/step - conv2d_58_loss: 25.2532 - conv2d_66_loss: 46.3925 - conv2d_74_loss: 54.6415 - loss: 130.3970 - val_conv2d_58_loss: 29.2811 - val_conv2d_66_loss: 109.3276 - val_conv2d_74_loss: 94.1902 - val_loss: 236.9735\n",
            "Epoch 6/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797ms/step - conv2d_58_loss: 21.3198 - conv2d_66_loss: 49.0348 - conv2d_74_loss: 57.8274 - loss: 132.3460libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 6: val_loss did not improve from 235.29443\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 904ms/step - conv2d_58_loss: 21.2700 - conv2d_66_loss: 48.9952 - conv2d_74_loss: 57.8707 - loss: 132.2995 - val_conv2d_58_loss: 27.6518 - val_conv2d_66_loss: 68.4012 - val_conv2d_74_loss: 172.2505 - val_loss: 272.4055\n",
            "Epoch 7/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800ms/step - conv2d_58_loss: 22.6079 - conv2d_66_loss: 50.0363 - conv2d_74_loss: 55.5663 - loss: 132.3063libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 7: val_loss improved from 235.29443 to 157.82260, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1s/step - conv2d_58_loss: 22.5745 - conv2d_66_loss: 49.9765 - conv2d_74_loss: 55.4942 - loss: 132.1409 - val_conv2d_58_loss: 33.6759 - val_conv2d_66_loss: 80.6449 - val_conv2d_74_loss: 39.4148 - val_loss: 157.8226\n",
            "Epoch 8/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804ms/step - conv2d_58_loss: 20.8352 - conv2d_66_loss: 44.5033 - conv2d_74_loss: 61.5369 - loss: 130.9555libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 8: val_loss did not improve from 157.82260\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 896ms/step - conv2d_58_loss: 20.8151 - conv2d_66_loss: 44.5123 - conv2d_74_loss: 61.4260 - loss: 130.8336 - val_conv2d_58_loss: 616.9879 - val_conv2d_66_loss: 74.6954 - val_conv2d_74_loss: 44.6434 - val_loss: 740.4399\n",
            "Epoch 9/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802ms/step - conv2d_58_loss: 19.7703 - conv2d_66_loss: 40.8925 - conv2d_74_loss: 54.4173 - loss: 119.1885libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 9: val_loss did not improve from 157.82260\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 974ms/step - conv2d_58_loss: 19.7739 - conv2d_66_loss: 40.9427 - conv2d_74_loss: 54.5025 - loss: 119.3270 - val_conv2d_58_loss: 83.9753 - val_conv2d_66_loss: 70.8279 - val_conv2d_74_loss: 46.4487 - val_loss: 205.2992\n",
            "Epoch 10/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793ms/step - conv2d_58_loss: 21.2400 - conv2d_66_loss: 40.1069 - conv2d_74_loss: 51.7720 - loss: 117.1360libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 10: val_loss did not improve from 157.82260\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 983ms/step - conv2d_58_loss: 21.2090 - conv2d_66_loss: 40.1395 - conv2d_74_loss: 51.7413 - loss: 117.1062 - val_conv2d_58_loss: 40.5780 - val_conv2d_66_loss: 88.2727 - val_conv2d_74_loss: 47.6089 - val_loss: 180.3809\n",
            "Epoch 11/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804ms/step - conv2d_58_loss: 19.7492 - conv2d_66_loss: 41.7451 - conv2d_74_loss: 50.4911 - loss: 115.8827libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 11: val_loss improved from 157.82260 to 131.56412, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - conv2d_58_loss: 19.7513 - conv2d_66_loss: 41.7739 - conv2d_74_loss: 50.5898 - loss: 116.0121 - val_conv2d_58_loss: 23.3048 - val_conv2d_66_loss: 59.6554 - val_conv2d_74_loss: 44.7393 - val_loss: 131.5641\n",
            "Epoch 12/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812ms/step - conv2d_58_loss: 18.7860 - conv2d_66_loss: 40.0330 - conv2d_74_loss: 45.5632 - loss: 108.2314libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 12: val_loss improved from 131.56412 to 112.21625, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - conv2d_58_loss: 18.7629 - conv2d_66_loss: 39.9806 - conv2d_74_loss: 45.4881 - loss: 108.0802 - val_conv2d_58_loss: 17.8581 - val_conv2d_66_loss: 51.6991 - val_conv2d_74_loss: 38.8897 - val_loss: 112.2162\n",
            "Epoch 13/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - conv2d_58_loss: 15.5200 - conv2d_66_loss: 49.2298 - conv2d_74_loss: 53.2303 - loss: 121.7248libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 13: val_loss did not improve from 112.21625\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 854ms/step - conv2d_58_loss: 15.5455 - conv2d_66_loss: 49.0172 - conv2d_74_loss: 53.1202 - loss: 121.4270 - val_conv2d_58_loss: 26.4163 - val_conv2d_66_loss: 55.0037 - val_conv2d_74_loss: 42.2467 - val_loss: 127.3490\n",
            "Epoch 14/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771ms/step - conv2d_58_loss: 20.7688 - conv2d_66_loss: 31.8535 - conv2d_74_loss: 36.3287 - loss: 92.6126libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 14: val_loss improved from 112.21625 to 109.88954, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - conv2d_58_loss: 20.7356 - conv2d_66_loss: 31.7854 - conv2d_74_loss: 36.3924 - loss: 92.5750 - val_conv2d_58_loss: 21.5587 - val_conv2d_66_loss: 50.6819 - val_conv2d_74_loss: 33.9614 - val_loss: 109.8895\n",
            "Epoch 15/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - conv2d_58_loss: 18.6748 - conv2d_66_loss: 32.5764 - conv2d_74_loss: 32.7452 - loss: 87.6814libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 15: val_loss improved from 109.88954 to 107.55117, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - conv2d_58_loss: 18.6863 - conv2d_66_loss: 32.4749 - conv2d_74_loss: 32.7775 - loss: 87.6236 - val_conv2d_58_loss: 29.0935 - val_conv2d_66_loss: 45.4794 - val_conv2d_74_loss: 29.3184 - val_loss: 107.5512\n",
            "Epoch 16/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727ms/step - conv2d_58_loss: 18.0153 - conv2d_66_loss: 30.1094 - conv2d_74_loss: 41.1620 - loss: 92.9345libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 16: val_loss did not improve from 107.55117\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 817ms/step - conv2d_58_loss: 18.0212 - conv2d_66_loss: 30.0670 - conv2d_74_loss: 41.1277 - loss: 92.8635 - val_conv2d_58_loss: 24.8522 - val_conv2d_66_loss: 51.8962 - val_conv2d_74_loss: 38.7596 - val_loss: 119.1358\n",
            "Epoch 17/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740ms/step - conv2d_58_loss: 17.5308 - conv2d_66_loss: 31.6057 - conv2d_74_loss: 32.5358 - loss: 85.3119libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 17: val_loss did not improve from 107.55117\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 839ms/step - conv2d_58_loss: 17.5168 - conv2d_66_loss: 31.5133 - conv2d_74_loss: 32.5597 - loss: 85.2296 - val_conv2d_58_loss: 129.5302 - val_conv2d_66_loss: 49.8809 - val_conv2d_74_loss: 31.7899 - val_loss: 214.8701\n",
            "Epoch 18/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750ms/step - conv2d_58_loss: 14.4881 - conv2d_66_loss: 26.9027 - conv2d_74_loss: 39.0583 - loss: 84.1134libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 18: val_loss did not improve from 107.55117\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 837ms/step - conv2d_58_loss: 14.4664 - conv2d_66_loss: 26.8503 - conv2d_74_loss: 38.9983 - loss: 83.9792 - val_conv2d_58_loss: 32.4471 - val_conv2d_66_loss: 60.8936 - val_conv2d_74_loss: 47.2562 - val_loss: 144.2522\n",
            "Epoch 19/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755ms/step - conv2d_58_loss: 16.7549 - conv2d_66_loss: 28.1701 - conv2d_74_loss: 38.6487 - loss: 87.2261libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 19: val_loss did not improve from 107.55117\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 865ms/step - conv2d_58_loss: 16.7093 - conv2d_66_loss: 28.0924 - conv2d_74_loss: 38.5484 - loss: 87.0024 - val_conv2d_58_loss: 34.0470 - val_conv2d_66_loss: 75.4657 - val_conv2d_74_loss: 85.4439 - val_loss: 198.5907\n",
            "Epoch 20/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762ms/step - conv2d_58_loss: 13.2374 - conv2d_66_loss: 20.7476 - conv2d_74_loss: 31.2479 - loss: 68.8567libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 20: val_loss did not improve from 107.55117\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 848ms/step - conv2d_58_loss: 13.2366 - conv2d_66_loss: 20.7685 - conv2d_74_loss: 31.1812 - loss: 68.8099 - val_conv2d_58_loss: 26.2498 - val_conv2d_66_loss: 35.9059 - val_conv2d_74_loss: 46.7188 - val_loss: 112.4762\n",
            "Epoch 21/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823ms/step - conv2d_58_loss: 11.9940 - conv2d_66_loss: 22.1579 - conv2d_74_loss: 29.3958 - loss: 67.1317libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 21: val_loss did not improve from 107.55117\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 911ms/step - conv2d_58_loss: 11.9869 - conv2d_66_loss: 22.1277 - conv2d_74_loss: 29.4453 - loss: 67.1435 - val_conv2d_58_loss: 21.7614 - val_conv2d_66_loss: 33.9451 - val_conv2d_74_loss: 58.1391 - val_loss: 117.3745\n",
            "Epoch 22/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788ms/step - conv2d_58_loss: 11.5924 - conv2d_66_loss: 21.7188 - conv2d_74_loss: 30.6776 - loss: 67.5012libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 22: val_loss improved from 107.55117 to 73.32509, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - conv2d_58_loss: 11.5966 - conv2d_66_loss: 21.7169 - conv2d_74_loss: 30.6243 - loss: 67.4500 - val_conv2d_58_loss: 14.3827 - val_conv2d_66_loss: 23.8275 - val_conv2d_74_loss: 31.6391 - val_loss: 73.3251\n",
            "Epoch 23/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815ms/step - conv2d_58_loss: 13.3479 - conv2d_66_loss: 21.5234 - conv2d_74_loss: 31.0225 - loss: 69.3696libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 23: val_loss improved from 73.32509 to 68.27330, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - conv2d_58_loss: 13.3179 - conv2d_66_loss: 21.4871 - conv2d_74_loss: 30.9692 - loss: 69.2501 - val_conv2d_58_loss: 13.3516 - val_conv2d_66_loss: 27.7796 - val_conv2d_74_loss: 23.6689 - val_loss: 68.2733\n",
            "Epoch 24/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798ms/step - conv2d_58_loss: 10.7208 - conv2d_66_loss: 19.3766 - conv2d_74_loss: 29.6743 - loss: 63.2322libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 24: val_loss did not improve from 68.27330\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 908ms/step - conv2d_58_loss: 10.7068 - conv2d_66_loss: 19.3990 - conv2d_74_loss: 29.6669 - loss: 63.2330 - val_conv2d_58_loss: 18.7431 - val_conv2d_66_loss: 29.3658 - val_conv2d_74_loss: 19.3364 - val_loss: 70.8705\n",
            "Epoch 25/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801ms/step - conv2d_58_loss: 11.3859 - conv2d_66_loss: 20.6174 - conv2d_74_loss: 28.3449 - loss: 63.7705libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 25: val_loss improved from 68.27330 to 54.15637, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - conv2d_58_loss: 11.3663 - conv2d_66_loss: 20.5909 - conv2d_74_loss: 28.2417 - loss: 63.6212 - val_conv2d_58_loss: 11.3773 - val_conv2d_66_loss: 21.2769 - val_conv2d_74_loss: 18.0853 - val_loss: 54.1564\n",
            "Epoch 26/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803ms/step - conv2d_58_loss: 11.0662 - conv2d_66_loss: 18.9846 - conv2d_74_loss: 26.3467 - loss: 59.8147libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 26: val_loss did not improve from 54.15637\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 915ms/step - conv2d_58_loss: 11.0610 - conv2d_66_loss: 18.9925 - conv2d_74_loss: 26.3229 - loss: 59.7936 - val_conv2d_58_loss: 11.9673 - val_conv2d_66_loss: 21.2303 - val_conv2d_74_loss: 20.1372 - val_loss: 56.7610\n",
            "Epoch 27/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799ms/step - conv2d_58_loss: 9.5543 - conv2d_66_loss: 17.3951 - conv2d_74_loss: 24.8832 - loss: 55.2519libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 27: val_loss improved from 54.15637 to 50.26838, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - conv2d_58_loss: 9.5577 - conv2d_66_loss: 17.3871 - conv2d_74_loss: 24.8319 - loss: 55.1958 - val_conv2d_58_loss: 10.6917 - val_conv2d_66_loss: 19.7787 - val_conv2d_74_loss: 16.3906 - val_loss: 50.2684\n",
            "Epoch 28/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794ms/step - conv2d_58_loss: 9.9681 - conv2d_66_loss: 17.9619 - conv2d_74_loss: 36.5855 - loss: 67.9140libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 28: val_loss did not improve from 50.26838\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 903ms/step - conv2d_58_loss: 9.9673 - conv2d_66_loss: 17.9513 - conv2d_74_loss: 36.3142 - loss: 67.6311 - val_conv2d_58_loss: 10.2105 - val_conv2d_66_loss: 22.5093 - val_conv2d_74_loss: 19.4938 - val_loss: 55.5903\n",
            "Epoch 29/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790ms/step - conv2d_58_loss: 8.6964 - conv2d_66_loss: 16.3546 - conv2d_74_loss: 35.8162 - loss: 64.2335libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 29: val_loss did not improve from 50.26838\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 882ms/step - conv2d_58_loss: 8.7132 - conv2d_66_loss: 16.3645 - conv2d_74_loss: 35.5580 - loss: 64.0017 - val_conv2d_58_loss: 12.1353 - val_conv2d_66_loss: 26.6107 - val_conv2d_74_loss: 24.5224 - val_loss: 66.6247\n",
            "Epoch 30/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773ms/step - conv2d_58_loss: 8.2737 - conv2d_66_loss: 16.6393 - conv2d_74_loss: 21.4765 - loss: 49.7377libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 30: val_loss did not improve from 50.26838\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 873ms/step - conv2d_58_loss: 8.2878 - conv2d_66_loss: 16.6435 - conv2d_74_loss: 21.5038 - loss: 49.7833 - val_conv2d_58_loss: 13.4726 - val_conv2d_66_loss: 27.8137 - val_conv2d_74_loss: 15.7412 - val_loss: 60.3622\n",
            "Epoch 31/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773ms/step - conv2d_58_loss: 8.4253 - conv2d_66_loss: 16.9312 - conv2d_74_loss: 19.4158 - loss: 48.0997libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 31: val_loss did not improve from 50.26838\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 867ms/step - conv2d_58_loss: 8.4444 - conv2d_66_loss: 16.9214 - conv2d_74_loss: 19.4402 - loss: 48.1334 - val_conv2d_58_loss: 12.2676 - val_conv2d_66_loss: 20.1470 - val_conv2d_74_loss: 17.3533 - val_loss: 53.0874\n",
            "Epoch 32/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770ms/step - conv2d_58_loss: 8.6333 - conv2d_66_loss: 15.3013 - conv2d_74_loss: 21.6264 - loss: 48.8772libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 32: val_loss did not improve from 50.26838\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 863ms/step - conv2d_58_loss: 8.6443 - conv2d_66_loss: 15.3057 - conv2d_74_loss: 21.5913 - loss: 48.8574 - val_conv2d_58_loss: 10.0031 - val_conv2d_66_loss: 22.3370 - val_conv2d_74_loss: 19.6852 - val_loss: 55.3287\n",
            "Epoch 33/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765ms/step - conv2d_58_loss: 8.0058 - conv2d_66_loss: 16.3965 - conv2d_74_loss: 32.5868 - loss: 60.2916libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 33: val_loss did not improve from 50.26838\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 880ms/step - conv2d_58_loss: 8.0179 - conv2d_66_loss: 16.4144 - conv2d_74_loss: 32.4549 - loss: 60.1896 - val_conv2d_58_loss: 9.6835 - val_conv2d_66_loss: 18.9890 - val_conv2d_74_loss: 21.6358 - val_loss: 53.6089\n",
            "Epoch 34/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764ms/step - conv2d_58_loss: 7.8110 - conv2d_66_loss: 15.2038 - conv2d_74_loss: 24.7207 - loss: 51.0291libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 34: val_loss did not improve from 50.26838\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 854ms/step - conv2d_58_loss: 7.8341 - conv2d_66_loss: 15.2154 - conv2d_74_loss: 24.6866 - loss: 51.0296 - val_conv2d_58_loss: 12.4151 - val_conv2d_66_loss: 21.4859 - val_conv2d_74_loss: 17.5269 - val_loss: 54.7169\n",
            "Epoch 35/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763ms/step - conv2d_58_loss: 7.5126 - conv2d_66_loss: 13.6198 - conv2d_74_loss: 28.7438 - loss: 53.1635libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 35: val_loss did not improve from 50.26838\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 860ms/step - conv2d_58_loss: 7.5246 - conv2d_66_loss: 13.6407 - conv2d_74_loss: 28.6315 - loss: 53.0841 - val_conv2d_58_loss: 9.4305 - val_conv2d_66_loss: 21.4417 - val_conv2d_74_loss: 18.3628 - val_loss: 52.5300\n",
            "Epoch 36/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762ms/step - conv2d_58_loss: 7.6684 - conv2d_66_loss: 15.0591 - conv2d_74_loss: 27.9121 - loss: 53.9358libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 36: val_loss improved from 50.26838 to 47.36380, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - conv2d_58_loss: 7.6902 - conv2d_66_loss: 15.0555 - conv2d_74_loss: 27.7947 - loss: 53.8366 - val_conv2d_58_loss: 11.2929 - val_conv2d_66_loss: 17.1433 - val_conv2d_74_loss: 15.6291 - val_loss: 47.3638\n",
            "Epoch 37/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801ms/step - conv2d_58_loss: 6.9441 - conv2d_66_loss: 15.1506 - conv2d_74_loss: 29.7552 - loss: 55.1477libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 37: val_loss did not improve from 47.36380\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 906ms/step - conv2d_58_loss: 6.9630 - conv2d_66_loss: 15.1494 - conv2d_74_loss: 29.5782 - loss: 54.9884 - val_conv2d_58_loss: 10.1678 - val_conv2d_66_loss: 22.3275 - val_conv2d_74_loss: 16.9110 - val_loss: 52.7020\n",
            "Epoch 38/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805ms/step - conv2d_58_loss: 7.6475 - conv2d_66_loss: 14.3129 - conv2d_74_loss: 17.9488 - loss: 43.1965libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 38: val_loss did not improve from 47.36380\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 907ms/step - conv2d_58_loss: 7.6485 - conv2d_66_loss: 14.3262 - conv2d_74_loss: 17.9719 - loss: 43.2337 - val_conv2d_58_loss: 13.7183 - val_conv2d_66_loss: 18.2679 - val_conv2d_74_loss: 13.6811 - val_loss: 48.9336\n",
            "Epoch 39/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793ms/step - conv2d_58_loss: 8.1844 - conv2d_66_loss: 13.7174 - conv2d_74_loss: 17.2078 - loss: 42.3756libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 39: val_loss did not improve from 47.36380\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 884ms/step - conv2d_58_loss: 8.1835 - conv2d_66_loss: 13.7263 - conv2d_74_loss: 17.2221 - loss: 42.3979 - val_conv2d_58_loss: 10.6145 - val_conv2d_66_loss: 17.6919 - val_conv2d_74_loss: 16.1758 - val_loss: 47.7418\n",
            "Epoch 40/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804ms/step - conv2d_58_loss: 7.6922 - conv2d_66_loss: 13.5490 - conv2d_74_loss: 23.5895 - loss: 48.0907libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 40: val_loss improved from 47.36380 to 45.19244, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - conv2d_58_loss: 7.6961 - conv2d_66_loss: 13.5476 - conv2d_74_loss: 23.5593 - loss: 48.0629 - val_conv2d_58_loss: 10.0617 - val_conv2d_66_loss: 17.7301 - val_conv2d_74_loss: 14.1505 - val_loss: 45.1924\n",
            "Epoch 41/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803ms/step - conv2d_58_loss: 7.2344 - conv2d_66_loss: 13.5831 - conv2d_74_loss: 23.3327 - loss: 47.4026libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 41: val_loss did not improve from 45.19244\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 894ms/step - conv2d_58_loss: 7.2452 - conv2d_66_loss: 13.5879 - conv2d_74_loss: 23.2389 - loss: 47.3245 - val_conv2d_58_loss: 9.5039 - val_conv2d_66_loss: 17.3823 - val_conv2d_74_loss: 16.2953 - val_loss: 46.4325\n",
            "Epoch 42/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799ms/step - conv2d_58_loss: 7.2982 - conv2d_66_loss: 13.0520 - conv2d_74_loss: 17.8391 - loss: 41.4347libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 42: val_loss did not improve from 45.19244\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 979ms/step - conv2d_58_loss: 7.2969 - conv2d_66_loss: 13.0564 - conv2d_74_loss: 17.8058 - loss: 41.4044 - val_conv2d_58_loss: 13.6820 - val_conv2d_66_loss: 19.0461 - val_conv2d_74_loss: 14.6340 - val_loss: 50.5829\n",
            "Epoch 43/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806ms/step - conv2d_58_loss: 6.7640 - conv2d_66_loss: 11.5620 - conv2d_74_loss: 19.8499 - loss: 41.3907libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 43: val_loss improved from 45.19244 to 40.21530, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - conv2d_58_loss: 6.7777 - conv2d_66_loss: 11.5882 - conv2d_74_loss: 19.8522 - loss: 41.4327 - val_conv2d_58_loss: 8.8198 - val_conv2d_66_loss: 14.9641 - val_conv2d_74_loss: 13.2113 - val_loss: 40.2153\n",
            "Epoch 44/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805ms/step - conv2d_58_loss: 6.6816 - conv2d_66_loss: 12.5309 - conv2d_74_loss: 19.9948 - loss: 42.4310libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 44: val_loss did not improve from 40.21530\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 897ms/step - conv2d_58_loss: 6.6886 - conv2d_66_loss: 12.5524 - conv2d_74_loss: 19.9598 - loss: 42.4245 - val_conv2d_58_loss: 8.2041 - val_conv2d_66_loss: 16.3069 - val_conv2d_74_loss: 12.9753 - val_loss: 40.7047\n",
            "Epoch 45/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796ms/step - conv2d_58_loss: 6.2668 - conv2d_66_loss: 11.9650 - conv2d_74_loss: 19.0487 - loss: 40.4993libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 45: val_loss did not improve from 40.21530\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 888ms/step - conv2d_58_loss: 6.2742 - conv2d_66_loss: 11.9851 - conv2d_74_loss: 19.0570 - loss: 40.5350 - val_conv2d_58_loss: 9.5585 - val_conv2d_66_loss: 14.3796 - val_conv2d_74_loss: 14.5333 - val_loss: 41.6952\n",
            "Epoch 46/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781ms/step - conv2d_58_loss: 6.9436 - conv2d_66_loss: 11.7479 - conv2d_74_loss: 15.4821 - loss: 37.3989libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 46: val_loss improved from 40.21530 to 39.55689, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 1s/step - conv2d_58_loss: 6.9454 - conv2d_66_loss: 11.7645 - conv2d_74_loss: 15.5340 - loss: 37.4691 - val_conv2d_58_loss: 8.6620 - val_conv2d_66_loss: 14.6389 - val_conv2d_74_loss: 13.0368 - val_loss: 39.5569\n",
            "Epoch 47/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759ms/step - conv2d_58_loss: 6.8017 - conv2d_66_loss: 12.1601 - conv2d_74_loss: 14.8430 - loss: 37.0235libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 47: val_loss did not improve from 39.55689\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 851ms/step - conv2d_58_loss: 6.8011 - conv2d_66_loss: 12.1640 - conv2d_74_loss: 14.8629 - loss: 37.0466 - val_conv2d_58_loss: 9.7892 - val_conv2d_66_loss: 16.7550 - val_conv2d_74_loss: 13.7405 - val_loss: 43.4942\n",
            "Epoch 48/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - conv2d_58_loss: 6.9285 - conv2d_66_loss: 10.1900 - conv2d_74_loss: 16.1912 - loss: 36.5203libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 48: val_loss did not improve from 39.55689\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 862ms/step - conv2d_58_loss: 6.9347 - conv2d_66_loss: 10.2160 - conv2d_74_loss: 16.2214 - loss: 36.5827 - val_conv2d_58_loss: 8.4658 - val_conv2d_66_loss: 16.1091 - val_conv2d_74_loss: 13.3723 - val_loss: 41.1581\n",
            "Epoch 49/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756ms/step - conv2d_58_loss: 6.4455 - conv2d_66_loss: 12.2913 - conv2d_74_loss: 17.7914 - loss: 39.7379libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 49: val_loss improved from 39.55689 to 38.01147, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - conv2d_58_loss: 6.4417 - conv2d_66_loss: 12.2791 - conv2d_74_loss: 17.8342 - loss: 39.7647 - val_conv2d_58_loss: 9.0042 - val_conv2d_66_loss: 14.1960 - val_conv2d_74_loss: 11.6122 - val_loss: 38.0115\n",
            "Epoch 50/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761ms/step - conv2d_58_loss: 5.9565 - conv2d_66_loss: 11.2975 - conv2d_74_loss: 15.7080 - loss: 36.1569libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 50: val_loss did not improve from 38.01147\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 861ms/step - conv2d_58_loss: 5.9679 - conv2d_66_loss: 11.3136 - conv2d_74_loss: 15.7134 - loss: 36.1898 - val_conv2d_58_loss: 8.4379 - val_conv2d_66_loss: 18.2402 - val_conv2d_74_loss: 14.1697 - val_loss: 44.0390\n",
            "Epoch 51/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764ms/step - conv2d_58_loss: 6.0449 - conv2d_66_loss: 11.2333 - conv2d_74_loss: 13.1513 - loss: 33.6223libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 51: val_loss did not improve from 38.01147\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 856ms/step - conv2d_58_loss: 6.0461 - conv2d_66_loss: 11.2463 - conv2d_74_loss: 13.2135 - loss: 33.6985 - val_conv2d_58_loss: 9.9553 - val_conv2d_66_loss: 13.3300 - val_conv2d_74_loss: 12.2325 - val_loss: 38.6950\n",
            "Epoch 52/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - conv2d_58_loss: 5.9844 - conv2d_66_loss: 10.3410 - conv2d_74_loss: 14.8928 - loss: 34.3967libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 52: val_loss improved from 38.01147 to 37.65513, saving model to model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - conv2d_58_loss: 5.9909 - conv2d_66_loss: 10.3555 - conv2d_74_loss: 14.9553 - loss: 34.4801 - val_conv2d_58_loss: 8.2129 - val_conv2d_66_loss: 13.8860 - val_conv2d_74_loss: 12.3831 - val_loss: 37.6551\n",
            "Epoch 53/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796ms/step - conv2d_58_loss: 6.4760 - conv2d_66_loss: 9.9512 - conv2d_74_loss: 12.6564 - loss: 32.2585libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 53: val_loss did not improve from 37.65513\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - conv2d_58_loss: 6.4684 - conv2d_66_loss: 9.9745 - conv2d_74_loss: 12.7195 - loss: 32.3374 - val_conv2d_58_loss: 8.2190 - val_conv2d_66_loss: 14.4389 - val_conv2d_74_loss: 13.0512 - val_loss: 38.8803\n",
            "Epoch 54/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825ms/step - conv2d_58_loss: 6.3045 - conv2d_66_loss: 10.3324 - conv2d_74_loss: 11.9912 - loss: 31.7944libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\n",
            "Epoch 54: val_loss did not improve from 37.65513\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 978ms/step - conv2d_58_loss: 6.2957 - conv2d_66_loss: 10.3431 - conv2d_74_loss: 12.0252 - loss: 31.8301 - val_conv2d_58_loss: 8.3810 - val_conv2d_66_loss: 15.4824 - val_conv2d_74_loss: 13.2079 - val_loss: 40.2228\n",
            "Epoch 55/100\n",
            "\u001b[1m23/42\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 791ms/step - conv2d_58_loss: 5.7231 - conv2d_66_loss: 9.9343 - conv2d_74_loss: 10.1355 - loss: 28.9407Traceback (most recent call last):\n",
            "  File \"/content/train.py\", line 69, in <module>\n",
            "    yolo_model.fit(dataset_train, epochs=epochs, steps_per_epoch=step_per_epoch,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n",
            "    logs = self.train_function(iterator)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n",
            "    if not opt_outputs.has_value():\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\", line 176, in has_value\n",
            "    return gen_optional_ops.optional_has_value(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\", line 172, in optional_has_value\n",
            "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "bttkgWWx1mgk",
        "outputId": "86fc2338-8d5d-4815-b55c-a8d8b7c88710"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-07-01 17:48:58.890082: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751392138.911385   15490 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751392138.917601   15490 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-01 17:48:58.939147: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-07-01 17:49:03.699185: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1751392143.699353   15490 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Tải mô hình thành công!\n",
            "Bắt đầu đánh giá trên tập validation...\n",
            "  0% 0/170 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1751392147.665882   15538 service.cc:148] XLA service 0x7d0e84052460 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1751392147.665923   15538 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-07-01 17:49:07.722698: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1751392148.063153   15538 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
            "I0000 00:00:1751392151.180097   15538 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            " 22% 38/170 [00:10<00:37,  3.51it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluate.py\", line 194, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluate.py\", line 120, in main\n",
            "    pred_boxes, pred_scores, pred_class_ids = get_model_predictions(model, image_path)\n",
            "                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/evaluate.py\", line 25, in get_model_predictions\n",
            "    raw_predictions = model.predict(img_expanded)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 562, in predict\n",
            "    batch_outputs = self.predict_function(data)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n",
            "    results = tracing_compilation.call_function(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
            "    return function._call_flat(  # pylint: disable=protected-access\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1322, in _call_flat\n",
            "    return self._inference_function.call_preflattened(args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
            "    flat_outputs = self.call_flat(*args)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
            "    outputs = self._bound_context.call_function(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 1683, in call_function\n",
            "    outputs = execute.execute(\n",
            "              ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
            "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python evaluate.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9f56fa9",
        "outputId": "5c52f2fa-bfd5-414d-93d5-f01f32d341cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5cecf6a"
      },
      "outputs": [],
      "source": [
        "! cp model.h5 /content/drive/MyDrive/model.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bb33c902"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/store-model-pre/yoloV3_version_1/model.h5 ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzdSX5SE3hzV"
      },
      "outputs": [],
      "source": [
        "! cp model.h5 /content/drive/MyDrive/store-model-pre/yoloV3_version_1/model.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7881b0d6"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/store-model-pre/yoloV3_version_1/data/images/* data/images/\n",
        "! cp /content/drive/MyDrive/store-model-pre/yoloV3_version_1/data/annotations/* data/annotations/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sDHQ9-84NowT"
      },
      "outputs": [],
      "source": [
        "! cp -r /content/drive/MyDrive/store-model-pre/yoloV3_version_1/data ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a019355a"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/store-model-pre/yoloV3_version_1/data/images/* data/images/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFfGomVtfzw8"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/store-model-pre/yoloV3_version_1/data/annotations/* data/annotations/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}